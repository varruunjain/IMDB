{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import time\n",
    "import re\n",
    "%matplotlib inline\n",
    "pd.set_option(\"display.max_rows\",25)\n",
    "pd.set_option(\"display.max_columns\",15)\n",
    "pd.options.display.float_format = \"{:.2f}\".format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATA SCRAPPING**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generating the listing urls on yearly basis\n",
    "year=['2010','2011','2012','2013','2014','2015',\"2016\",\"2017\"]\n",
    "\n",
    "pagerange=np.arange(1,11)\n",
    "url=[]\n",
    "dict_years_list={}\n",
    "\n",
    "\n",
    "def page_range_url(year):\n",
    "    for i,y in enumerate(year):\n",
    "        url.append(\"http://www.imdb.com/search/title?year=\"+y+\"&title_type=feature&\")\n",
    "        dict_years_list[y]=[]\n",
    "    print(url)    \n",
    "    for d, u in zip(dict_years_list.keys(),url):\n",
    "        #for u in url:\n",
    "        \n",
    "            for itr in pagerange:\n",
    "                dict_years_list[d].append(u+\"&page=\"+str(itr)+\"&ref_=adv_nxt\")\n",
    "    return dict_years_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Scrapping the list search of urls year wise.\n",
    "def scrap_url(dict_years_list):\n",
    "    \n",
    "    page=dict(zip(dict_years_list.keys(), [None]*len(dict_years_list.keys())))   \n",
    "    for idx, value in (dict_years_list.items()):\n",
    "        li=[]\n",
    "        \n",
    "        for i in value:\n",
    "            print(i)\n",
    "            li.append(requests.get(i).text)\n",
    "            \n",
    "        print(idx)   \n",
    "        page[idx]=li \n",
    "    return page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_year=page_range_url(year) # Generating the URL list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_title_links=scrap_url(dict_year) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#pickling the list of all URLS\n",
    "pd.to_pickle(all_title_links,\"all_title_links.pkl\") \n",
    "links=pd.read_pickle(\"all_title_links.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "links.keys()\n",
    "list_2014=[]\n",
    "list_2015=[]\n",
    "list_2016=[]\n",
    "list_2017=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scrapping the list YEAR wise\n",
    "def scrap_listing_url(listing):\n",
    "    listof=[]\n",
    "    for i,title in enumerate(listing):\n",
    "        listof.append(BeautifulSoup(title,'lxml'))\n",
    "    \n",
    "    return listof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_2015=scrap_listing_url(links['2015'])\n",
    "list_2016=scrap_listing_url(links[\"2016\"])\n",
    "list_2017=scrap_listing_url(links[\"2017\"])\n",
    "list_2014=scrap_listing_url(links[\"2014\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extracting list title links\n",
    "\n",
    "final_list_link=[]\n",
    "#final_list_name=[]\n",
    "def title_part_link(listyear):\n",
    "    \n",
    "    for t in listyear:\n",
    "        movie_links=[i.find('a')[\"href\"] for i in t.find(class_=\"article\").find_all(class_=\"lister-item-header\")]\n",
    "        final_list_link.append(movie_links)\n",
    "        #movie_name=[a.find('a').text for a in t.find(class_=\"article\").find_all(class_=\"lister-item-header\")]\n",
    "        #final_list_name.append(movie_name)\n",
    "    return (final_list_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Flattening the list of list\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "final_list_links=flatten(title_part_link(list_2016))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linker_2017=[]\n",
    "linker_2015=[]\n",
    "linker_2016=[]\n",
    "linker_2014=[]\n",
    "for f in final_list_links:\n",
    "    linker_2017.append(\"http://www.imdb.com/\"+f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pickling and retrieving \n",
    "\n",
    "pd.to_pickle(linker_2015,\"linker_2015.pkl\")\n",
    "pd.to_pickle(linker_2016,\"linker_2016.pkl\")\n",
    "pd.to_pickle(linker_2017,\"linker_2017.pkl\")\n",
    "pd.to_pickle(linker_2014,\"linker_2014.pkl\")\n",
    "\n",
    "linker_2014=pd.read_pickle(\"linker_2014.pkl\")\n",
    "linker_2015=pd.read_pickle(\"linker_2015.pkl\")\n",
    "linker_2016=pd.read_pickle(\"linker_2016.pkl\")\n",
    "linker_2017=pd.read_pickle(\"linker_2017.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scrapping the Final Title Page\n",
    "def scrap_title(linker):\n",
    "    listy=[]\n",
    "    for indx,l in enumerate (linker):\n",
    "        print(indx)\n",
    "        print(l)\n",
    "        listy.append(requests.get(l).text)\n",
    "    return listy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jumbo_2014_1=scrap_title(linker_2014)\n",
    "jumbo_2015_1=scrap_title(linker_2015)\n",
    "jumbo_2016_1=scrap_title(linker_2016)\n",
    "jumbo_2017_1=scrap_title(linker_2017)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#final content scrapper of the title of the movie\n",
    "def scrap_details(list_name):\n",
    "    import time\n",
    "    import re\n",
    "    budget=[]\n",
    "    cast=[]\n",
    "    plot=[]\n",
    "    budget=[]\n",
    "    gross_usa=[]\n",
    "    cumm_world=[]\n",
    "    director=[]\n",
    "    genre=[]\n",
    "    language=[]\n",
    "    country=[]\n",
    "    release_date=[]\n",
    "    num_reviews=[]\n",
    "    run_time=[]\n",
    "    content_rating=[]\n",
    "    rating=[]\n",
    "    name_movie=[]\n",
    "    for i,title in enumerate(list_name):\n",
    "        beauty=(BeautifulSoup(title,'lxml'))\n",
    "        casty=[]\n",
    "        print(i)\n",
    "#Movie Name    \n",
    "        name_movie.append(beauty.find(\"h1\",itemprop=\"name\").text.replace(u\"\\xa0\",\"\"))\n",
    "#Cast    \n",
    "        if(beauty.find_all(class_=\"itemprop\")!=None):\n",
    "            for element in beauty.find_all(class_=\"itemprop\"):\n",
    "                if(element.find('a') !=None):\n",
    "                    casty.append(element.find('a').text.replace(\"\\n\",\"\").strip())\n",
    "        else:\n",
    "            print(\"Yes\")\n",
    "            casty.append(None)    \n",
    "        cast.append(casty)        \n",
    "#Plot    \n",
    "        try:\n",
    "        \n",
    "            plot.append(beauty.find(class_=\"inline canwrap\",itemprop=\"description\").text)\n",
    "                \n",
    "        except:\n",
    "            print(\"No Plot\")\n",
    "            plot.append(None)\n",
    "#Genre            \n",
    "        for element in beauty.find_all(itemprop=\"genre\"):\n",
    "            c=element.find_all(\"a\")\n",
    "            t=[]\n",
    "            for itr in c:\n",
    "                if itr!=None:\n",
    "                    t.append(itr.text.strip())\n",
    "                else:\n",
    "                    t.append(None)\n",
    "        genre.append(t)      \n",
    "#Director    \n",
    "        try:\n",
    "        #if(beauty.find(class_=\"credit_summary_item\").find('a').text!=None):\n",
    "            director.append(beauty.find(class_=\"credit_summary_item\").find('a').text)\n",
    "        except:\n",
    "            director.append(None)\n",
    "#Language\n",
    "        if(beauty.find('h4', text=\"Language:\")!=None):\n",
    "            language.append(beauty.find('h4', text=\"Language:\").find_next_sibling().text)\n",
    "        else:\n",
    "            language.append(None)\n",
    "    \n",
    "#Country\n",
    "        if(beauty.find('h4', text=\"Country:\")!=None):\n",
    "            country.append(beauty.find('h4', text=\"Country:\").find_next_sibling().text)\n",
    "        else:\n",
    "            country.append(None)\n",
    "        \n",
    "#Release Date\n",
    "        if(beauty.find(\"meta\", itemprop=\"datePublished\")!=None):\n",
    "            release_date.append(beauty.find(\"meta\", itemprop=\"datePublished\")[\"content\"])\n",
    "        else:\n",
    "            release_date.append(None)\n",
    "        \n",
    "#Movie Run Time\n",
    "        if(beauty.find(\"h4\", text=\"Runtime:\")!=None):\n",
    "            run_time.append(beauty.find(\"h4\", text=\"Runtime:\").find_next_sibling().text.split(\" \")[0])\n",
    "        else:\n",
    "            run_time.append(None)\n",
    "        \n",
    "#Number of Revies\n",
    "        if(beauty.find(class_=\"ratingValue\")!= None):\n",
    "               num_reviews.append(beauty.find(class_=\"ratingValue\").find_next_sibling().text)\n",
    "        else:\n",
    "               num_reviews.append(None)\n",
    "    \n",
    "#Content Rating\n",
    "        if(beauty.find(\"meta\",itemprop=\"contentRating\")!=None):\n",
    "            content_rating.append(beauty.find(\"meta\",itemprop=\"contentRating\")[\"content\"])\n",
    "        else:\n",
    "            content_rating.append(None)\n",
    "#Rating (Censor)\n",
    "        if (beauty.find(\"span\",itemprop=\"ratingValue\")!=None):\n",
    "            rating.append(beauty.find(\"span\",itemprop=\"ratingValue\").text)\n",
    "        else:\n",
    "            rating.append(None)\n",
    "#Movie Budget    \n",
    "        if(beauty.find(\"h4\",text=\"Budget:\")!=None):\n",
    "            budget.append(beauty.find(\"h4\",text=\"Budget:\").next_sibling.replace(\"\\n\",\"\").strip().replace(\"$\",\"\"))\n",
    "        else:\n",
    "            budget.append(None)\n",
    "#Gross Collection USA\n",
    "        if(beauty.find(\"h4\",text=\"Gross USA:\")!=None):\n",
    "        \n",
    "            gross_usa.append(beauty.find(\"h4\",text=\"Gross USA:\").next_sibling.replace(\"\\n\",\"\").strip().replace(\"$\",\"\"))\n",
    "        else:    \n",
    "            gross_usa.append(None)\n",
    "#Gross Collections Worldwide\n",
    "        if(beauty.find(\"h4\",text=\"Cumulative Worldwide Gross:\")!=None):\n",
    "            cumm_world.append(beauty.find(\"h4\",text=\"Cumulative Worldwide Gross:\").next_sibling.replace(\"\\n\",\"\").strip().replace(\"$\",\"\"))\n",
    "        else:\n",
    "            cumm_world.append(None)\n",
    "    return name_movie,plot,cast,budget,rating,content_rating,gross_usa,cumm_world,num_reviews,run_time,language,director,genre,release_date,country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MOVIE,PLOT,CAST,BUDGET,RATING,CONTENT_RATING,GROSS_REV,CUMM_REV,REVIEWS,RUN_TIME,LANGUAGE,DIRECTOR,GENRE,RELEASE_DATE,COUNTRY=scrap_details(jumbo_2016_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_2016=pd.DataFrame({\"MOVIE\":MOVIE,\"CAST\":CAST\n",
    "#               ,\"BUDGET\":BUDGET,\"RATING\":RATING,\"CONTENT_RATING\":CONTENT_RATING,\n",
    "#               \"GROSS_REV\":GROSS_REV,\"CUMM_REV\":CUMM_REV,\"REVIEWS\":REVIEWS,\n",
    "#               \"RUN_TIME\":RUN_TIME,\"LANGUAGE\":LANGUAGE,\"DIRECTOR\":DIRECTOR,\"GENRE\":GENRE,\"RELEASE_DATE\":RELEASE_DATE,\"PLOT\":PLOT,\"COUNTRY\":COUNTRY})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.to_pickle(df_2016,\"df_2701_2016.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "433px",
    "left": "1336.67px",
    "right": "54.3333px",
    "top": "120px",
    "width": "316px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
